\documentclass[11pt]{article}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{subfigure}
\usepackage{lscape}
\usepackage{flafter}  % Don't place floats before their definition
\usepackage{bm}  % Define \bm{} to use bold math fonts
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{MnSymbol}
\usepackage{url}
\usepackage{natbib}
%\usepackage{fullpage}
\bibliographystyle{cbe}
\citestyle{aa}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage[vlined,algochapter,ruled]{algorithm2e}
%\usepackage[vlined,ruled]{algorithm2e}
%\SetKwComment{Comment}{$\triangleright\ $}{}

\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\algnewcommand\algorithmicswitch{\textbf{switch}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicdefault{\textbf{default}}
\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}%
\algdef{SE}[DEFAULT]{Default}{EndDefault}[1]{\algorithmicdefault\ #1}{\algorithmicend\ \algorithmicdefault}%
\algtext*{EndSwitch}%
\algtext*{EndCase}%
\algtext*{EndDefault}%

\DeclarePairedDelimiter\setsize{\lvert}{\rvert}%

\title{ \textbf{Efficient Implied Alignment}}
\author{Alex J. Washburn and Ward C. Wheeler\\
		Division of  Invertebrate Zoology\\
		American Museum of Natural History\\
		200 Central Park West\\
		New York, NY 10024-5192\\
		USA\\
		academia@recursion.ninja\\
		wheeler@amnh.org\\
		212-769-5754}
	%\date{}
\begin{document}

\maketitle
\begin{abstract}
  For a given binary tree $\mathcal{T}$ of $n$ leaves, each leaf containing a string of length at most $k$, and a binary string alignment function $\otimes$, an Implied Alignment \citep{Wheeler2003} can be generated to describe the alignment of a dynamic homology for $\mathcal{T}$. This is done by first decorating each node of the tree with an alignment context using the function $\otimes$ in a post order traversal, then by inferring from the internal node decorations on which edges all insertion and deletion events occurred during a subsequent pre-order traversal. Previous descriptions of generating an implied alignment suggest a technique of ``back-propagation'' which runs in $\mathcal{O}(n^2 * k^2)$ time. Here we describe a method for generating an implied alignment which runs in \textsc{$\mathcal{O}(n * k^{2-c})$} time by exploiting the monoid structure of a dynamic homology. This reduction in the time complexity of the procedure dramatically improves the utility of the procedure in generating multiple sequence alignments and their heuristic utility.
\end{abstract}
\newpage
\tableofcontents
\newpage

%\doublespacing
\section{Introduction}
Implied Alignment (IA) was proposed by \cite{Wheeler2003} as an adjunct to Direct Optimization (DO) \citep{Wheeler1996,VaronandWheeler2012} analysis of DNA sequence data for verification and more rapid heuristic analysis.
IA has been a component of POY \citep{Wheeleretal2015, POY5} since its inception.
More formal description of the algorithm was presented in \cite{Wheeleretal2006}.
Although originally designed for dynamic homology \citep{Wheeler2001} analysis, the procedure was first used as a stand-alone multiple sequence analysis (MSA) tool by \cite{WhitingAetal2006} in their analysis of skink relationships.  Furthermore, A. Whiting et al. found that IA was superior (in terms of tree optimality score) to other MSA methods in both parsimony and likelihood analyses.  
This observation has been repeated multiple times (e.g. \citealp{LindgrenandDaly2007, FordandWheeler2015}; summarized in \citealp{Wheeler2012}) and we have not yet come upon any counterexamples.    

The use of IA as an MSA algorithm as well as its use in the ``static approximation'' procedure, benefit greatly from improvements in the time-complexity of the algorithm.
The IA algorithm presented in this paper uses a pairwise string alignment function to perform an efficient multiple string alignment for a given binary tree describing the relationships of strings. 
The more similar the strings, the better the algorithm performs. 
While this algorithm has general use for performing an MSA, it is most particularly well suited for the alignment of biological sequences where the strings are highly similar and a binary tree describing the strings' relationship can be provided. 
We will provide an example of the IA algorithm's performance on biological data.

\textbf{TODO}
Here I can also define the parameters: binary tree, dynamic homology, pairwise alignment heuristic. Note the interplay between these, and any invariants that apply. Then describe the motivation for an implied alignment: as a visualization tool, a de novo alignment method, and as a static approximation heuristic component.

\section{Definition of the hueristic function}
In order for a logically consistent implied alignment to be inferred, there are constraints on the heuristic alignment function used to decorate the tree before the implied alignment algorithm is performed.
Let $\Sigma$ be a finite alphabet of symbols such that $\setsize{\Sigma} \geq 3$.
Let (--) be a gap symbol which will have a special meaning in the context of an alignment and (--) $\in \Sigma$.
Let $\mathcal{P}(x)$ be the powerset of x minus $\emptyset$.
Let $\Sigma_{\Gamma}$ be the alphabet of the following symbols:

\begin{align*}
  \Sigma_{\Gamma} &      = \textbf{ALIGN}  \;\;\;\;\;\,  \mathcal{P} (\Sigma) \;\; \mathcal{P} (\Sigma) \;\; \mathcal{P} (\Sigma)
\\                & \;\, | \;\; \textbf{DELETE} \;\;     \mathcal{P} (\Sigma) \;\; \mathcal{P} (\Sigma)
\\                & \;\, | \;\; \textbf{INSERT} \;\;\;\, \mathcal{P} (\Sigma) \;\; \quad\quad\;         \;\; \mathcal{P} (\Sigma)
\end{align*}

Let $\Sigma^{*}_{\Gamma}$ be the set of all finite strings over the alphabet $\Sigma_{\Gamma}$.
Let $\otimes \colon \Sigma^{*}_{\Gamma} \times \Sigma^{*}_{\Gamma} \mapsto \left(\mathbb{N}, \Sigma^{*}_{\Gamma}\right)$ be our heuristic function returning an alignment cost and alignment context.
It is often convenient to ignore the cost returned from the heuristic function and consider only the resulting alignment context. Therefore let $\oplus \colon \Sigma^{*}_{\Gamma} \times \Sigma^{*}_{\Gamma} \mapsto \Sigma^{*}_{\Gamma}$ be defined as $\otimes$ but ignoring the alignment cost of the result. 
The function $\oplus$ must be closed under $\Sigma^{*}_{\Gamma}$ and must be commutative. 
The function $\oplus$ need not be associative.
These constraints are necessary but not sufficient for a logically consistent implied alignment to be inferred on the heuristic alignment function.

\section{Definition of an example heuristic function}
We will provide one definition of $\otimes$ sufficient for the Implied Alignment algorithm, though there are other sufficient definitions of $\otimes$. 
One candidate function fitting the description of $\otimes$ can be defined by making a slight modification to the Needleman-Wunsch \cite{Needleman1970} algorithm for pairwise string alignment.
This algorithm is very similar to DO.

First we assure that the function is commutative by deterministically choosing which string is tied to the top (columns) of the alignment matrix and which string is tied to the left side (rows). 
We assign the input string based on the data they contain, ensuring commutivity. If this step is not taken, arbitrary biases choosen in the implementation details of the alignment matrix back-trace can cause the following $\otimes$ definition to violate commutivity. 
The longer string is tied to the top of the alignment matrix, the shorter string to the left side. If the strings are the same length, we take the larger string under the lexical ordering of thier elements and tie it to the top row, the lesser string is tied to the left side of the aligment matrix. 
In the case that the strings are equal, the alignment is trivial.

Next we apply the modified Needleman-Wunsch algorithm to generate the alignment matrix of the two strings. The "longer" string is tied to the top of the matrix and the "shorter" string is tied to the left column.

We perform a ``traceback'' through the generated alignment matrix in a manner similar to the Needleman-Wunsch. 
However, this traceback differs in one substantial detail. When using the directional arrows to determine which way to move through the matrix in the traceback, we also use the upward, leftward, and diagonal directional arrows to tag the element as either and insertion, deletion, or alignment event, respectively. 
By adding this additional tag of information to the pairwise alignment result, we can later consume the tags to when merging local, pairwise alignment to efficiently generate a multiple string alignment.
This additional tagging detail is the key difference between previous alignment methods and the one we present in this paper.

The example $\otimes$ function presented here runs in $\Theta\left( k^2 \right)$ time and space, where $k$ is the length of the longer string. This example function presents the tagging modification as an adaptation of the simple, well-understood Needleman-Wunsch algorithm for clairity. However, this tagging approach can be incorperated into more sophisticated pairwise string alignment algorithms. By using the method described by \cite{Ukkonen1985}, this algorithm's runtime could be improved to average case $\mathcal{O}\left( k * \log k \right)$ time in general, and near linear time on sequences of high similarity. By using the method described by \cite{Hirschberg1975}, this algorithm can be further improved to use $\mathcal{O}\left( k \right)$ space.

It is worth noting that $\sigma$ presented in the pseudocode below can represent a more complex metric, such as using affine or logrithmic affine gap costs.

\begin{algorithm}
  \caption{Example $\otimes$ definition}\label{pairwiseAlignment}
  \begin{algorithmic}[1]
    \Require{$lhs, rhs \in \Sigma_{\Gamma}^{*}$ }
    \Function{$\otimes$}{$\textit{lhs}, \textit{rhs}$}
      \newline
      \Comment{Conditionals here are required to ensure commutivity of $\otimes$.}
      \If    {$\textit{lhs} = \textit{rhs}$}
        \State \Return $\textit{lhs}$
      \ElsIf {$\textit{lhs} < \textit{rhs}$}
        \State \Return $\Call{matrixTraceback}{\sigma, \textit{lhs}, \textit{rhs}}$
      \Else
        \State \Return $\Call{matrixTraceback}{\sigma, \textit{rhs}, \textit{lhs}}$
      \EndIf
    \EndFunction  
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Generate the alignment matrix of $\otimes$}\label{matrixDefinition}
  \begin{algorithmic}[1]
    \Require{$lesser, longer \in \Sigma_{\Gamma}^{*}$}
    \Require{$\sigma \colon \left(( \Sigma_{\Gamma}, \Sigma_{\Gamma}\right) \mapsto \left(\mathbb{N}, \Sigma_{\Gamma} \right)$}
    \Require{$i \, \in \left[-1, \; \vert \textit{lesser} \,\;\vert - 1 \right] \subset \mathbb{Z}$}
    \Require{$j    \in \left[-1, \; \vert \textit{longer} \,  \vert - 1 \right] \subset \mathbb{Z}$}
    \Function{matrixDefinition}{$\textit{lesser}, \textit{longer}, \sigma, i, j$}
      \If   {$i < 0 \lor j < 0$} \Comment{Outside of matrix is infinite cost}
        \State \Return $\left( \infty, \nwarrow, \textbf{--} \right)$
      \ElsIf{$i = 0 \land j = 0$} \Comment{Handle the origin}
        \State \Return $\left( 0, \nwarrow, \textbf{--} \right)$
      \ElsIf{$j \neq 0 \land \textit{longer}_{j-1}      = \textbf{--}$} \Comment{Preserve input gap}
        \State $\left(\textit{leftCost}, \_, \_ \right) \gets \Call{matrixDefinition}{\textit{lesser}, \textit{longer}, \sigma, i, j - 1}$
        \State \Return $\left( \textit{leftCost}, \leftarrow, \textbf{--} \right)$ 
      \ElsIf{$i \neq 0 \land \textit{lesser}_{i-1} \,\; = \textbf{--}$} \Comment{Preserve input gap}
        \State $\left(\textit{aboveCost}, \_, \_ \right) \gets \Call{matrixDefinition}{\textit{lesser}, \textit{longer}, \sigma, i, j - 1}$
        \State \Return $\left( \textit{aboveCost}, \uparrow, \textbf{--} \right)$
      \Else \Comment{General recursive case}
        \State $x \gets \sigma \left(           \textit{longer}_{j-1}, \textit{lesser}_{i-1} \right)$
        \State $y \gets \sigma \left(           \textit{â€¢}it{longer}_{j-1}, \quad\quad\quad \textbf{--} \right)$
        \State $z \gets \sigma \left( \quad\quad\quad\;\, \textbf{--}, \textit{lesser}_{i-1} \right)$
        \State $\left( minCost, minDir, minElem \right) \gets \Call{getMinimal}{x, y, z}$
        \If {$\left( \textit{minDir}, \textit{minElem} \right) = \left( \nwarrow, \textbf{--} \right)$} \Comment{Aligned gap is insertion}
          \State \Return $\left( minCost, \leftarrow, \textbf{--} \right)$
        \Else 
          \State \Return $\left( minCost, minDir, minElem \right)$
        \EndIf
      \EndIf
    \EndFunction  
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Consume the alignment matrix of $\otimes$, returning the alignment and cost}\label{matrixTraceback}
  \begin{algorithmic}[1]
    \Require{$lesser, longer \in \Sigma_{\Gamma}^{*}$}
    \Require{$\sigma \colon \left( \Sigma_{\Gamma}, \Sigma_{\Gamma}\right) \mapsto \left(\mathbb{N}, \Sigma_{\Gamma} \right)$}

    \Function{matrixTraceback}{$\textit{lesser}, \textit{longer}$}
      \State $\left( i, j \right) \gets \left( \vert \textit{lesser} \;\vert - 1,\; \vert \textit{longer} \;\vert - 1 \right)$
      \State \Return $\left( alignedCost, \_, \_ \right) \gets \Call{matrixDefinition}{\textit{lesser}, \textit{longer}, \sigma, i, j}$
      \State $alignedStr \gets \left[ \,\right]$
      \While{$\left( i, j \right) > \left( 0, 0 \right)$}
        \State $\left( \_, dirArrow, elem \right) \gets \Call{matrixDefinition}{\textit{lesser}, \textit{longer}, \sigma, i, j}$
        \Switch{$\textit{dirArrow}$}
          \Case{$\leftarrow$}
            \State $\left( i, j\right) \gets \left( i \quad\;\;, j - 1       \right)$
            \State $nextElement \gets \textbf{DELETE} \;\;   elem \;\; \textit{longer}_{j-1}$
          \EndCase
          \Case{$\uparrow$}
            \State $\left( i, j\right) \gets \left( i - 1      , j \quad\;\; \right)$
            \State $nextElement \gets \textbf{INSERT} \;\;\; elem \hspace{1.9cm} \textit{lesser}_{i-1}$
          \EndCase
          \Case{$\nwarrow$}
            \State $\left( i, j\right) \gets \left( i - 1      , j - 1       \right)$
            \State $nextElement \gets \textbf{ALIGN} \quad\; elem \;\; \textit{longer}_{j-1} \;\; \textit{lesser}_{i-1}$
          \EndCase
        \EndSwitch
        \State $alignedStr \gets nextElement + alignedStr$
      \EndWhile
      \State \Return $\left(alignedCost, alignedStr \right)$
    \EndFunction  
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Get the minimal directional matrix context from the $3$ inputs}\label{getMinimal}
  \begin{algorithmic}[1]
    \Require{$\left(\;\;diagCost,\;\,diagElem \right) \in \left(\mathbb{N}, \Sigma_{\Gamma} \right)$}
    \Require{$\left(\, rightCost,   rightElem \right) \in \left(\mathbb{N}, \Sigma_{\Gamma} \right)$}         
    \Require{$\left(    downCost,    downElem \right) \in \left(\mathbb{N}, \Sigma_{\Gamma} \right)$}
    \Require{Total ordering over directional arrows defined as: $\nwarrow \; < \; \leftarrow \; < \; \uparrow$}
    \Function{getMinimal}{$ \, \left(\;\;diagCost,\;\,diagElem \right)$\newline\hspace*{3.85cm}
                          $,\, \left(\, rightCost,   rightElem \right)$\newline\hspace*{3.85cm}
                          $,\, \left(    downCost,    downElem \right)$\newline\hspace*{4cm}}
      \State \Return $minimumBy \; \left(\lambda \left(c, \_, d \right) \mapsto \textbf{comparing}\; c \; \textbf{then} \; d)\right)$\newline\hspace*{3.85cm}
      $[\, \left(\;\;diagCost, \;\,diagElem   \quad\;\;\,   ,      \nwarrow    \right)$\newline\hspace*{3.85cm}
      $,\, \left(\, rightCost,    rightElem \cup \textbf{--}, \, \leftarrow    \right)$\newline\hspace*{3.85cm}
      $,\, \left(    downCost,     downElem \cup \textbf{--}, \;   \uparrow \; \right)$\newline\hspace*{3.85cm}
      $]$
    \EndFunction  
  \end{algorithmic}
\end{algorithm}


\section{Description of post-order traversal}
The postorder traversal of the binary tree $\mathcal{T}$ is a straightforward procedure.
We will assign preliminary string alignment contexts and costs to each node of $\mathcal{T}$.
These preliminary string alignment contexts will be consumed to assign a final string alignment in a subsequent preorder traversal of the tree.
The postorder traversal described here is very similar to the  DO postorder traversal described by Wheeler.
The main difference is the use of a heuristic alignment function $\otimes$ which captures the alignment context of a subtree, instead of performing a traditional string alignment such as Needleman Wunsch.

Starting at the leaf nodes, we set the \textit{node.cost} field to be $0$.
Additionally if the string on the leaf node is of type $\Sigma^{*}$ and not of type $\Sigma^{*}_{\Gamma}$, we call $\Call{initializeString}{node.prelimString}$ on the string value to apply the transformation $\Sigma^{*} \mapsto \Sigma^{*}_{\Gamma}$.
That is to say, if the binary tree's leaf node has been decorated with a finite string of symbols from the alphabet $\Sigma$, and not a finite string of alignment contexts over the alphabet $\Sigma$, we lift the string's symbols into the appropriate aligmnent context.

On each internal node of the binary tree $\mathcal{T}$, we call $\otimes$ on the \textit{prelimString} fields of the node's left and right children.
The node's \textit{prelimString} field is assigned the result of the call to $\otimes$ and the node's  \textit{cost} field is assigned the sum of the node's left and right childern's \textit{cost} fields and the cost returned by the call to $\otimes$.
By performing this operation in a postorder traversal over the binary tree $\mathcal{T}$ we propogate the alignment contexts and cost returned from the calls to $\otimes$ up the tree from the leaves to the root.

After performing the postorder traversal, each internal node contains the alignment context information, and the cost of alignment, for it's entire subtree.
Consequently, the root node now contains the entire alignment context information of the leaf set of strings.
In the next step, we will consume this preliminary alignment context information on each node to efficiently perform an alignment on the strings.

Because the postorder traversal can be performed using any valid hueristic alignment function $\otimes$, the complexity of the postorder traversal is dependant on the complexity of the hueristic alignment function used. Let the complexity of $\otimes$ be defined as $H\left(k\right)$, where $k$ is the maximum string length of the leaf labels of the tree $\mathcal{T}$. Then postorder traversal runs in $\mathcal{O}(n * H(k))$ time and space, where $n$ is the number of leaves in the binary tree $\mathcal{T}$. If we were to use Ukkonnen's method with the example $\otimes$ function described above, the postorder traversal would run in $\mathcal{O}\left( n * k * \log \left( k \right) \right)$ average case time and space.

\section{Psuedocode of post-order traversal}

\begin{algorithm}
  \caption{Post-order Traversal}\label{postOrder}
  \begin{algorithmic}[1]
    \Require{$inputString \in \Sigma^{*}$ }
    \Function{initializeString}{$\textit{inputString}$}
      \State $i \gets \vert\textit{inputString} \;\vert - 1,$
      \While{$i \geq 0$}
        \State $\textit{inputString}_i \gets \textbf{ALIGN} \; \left\{ \textit{inputString}_i\right\} \left\{ \textit{inputString}_i \right\} \left\{ \textit{inputString}_ii \right\}$
      \EndWhile 
      \Return $\textit{inputString}$
    \EndFunction 
        
    \Require{A binary tree decorated with leaf labels $inputString \in \Sigma_{\Gamma}^{*}$ }
    \Ensure{A binary tree decorated with internal labels $prelimString \in \Sigma_{\Gamma}^{*}$ }
    %    \Procedure{postOrder(n)}{}
    \Function{postOrder}{$\textit{node}$}
      \If   {isLeaf ( $\textit{node}$ )}
        \State $\textit{node.cost} \gets 0$
%        \If {isOfType ($\Sigma^{*}$, $\textit{node.prelimString}$ )}
%          \State $\textit{node.prelimString} \gets \Call{initializeString}{node.prelimString}$
%sy        \EndIf
      \Else
        \State $\textit{lhs}  \gets \Call{postOrder}{\textit{node.children.first}}$
        \State $\textit{rhs}  \gets \Call{postOrder}{\textit{node.children.second}}$
        \State $\left(\textit{alignCost}, \textit{alignContext}\right) \gets \textit{lhs.prelimString} \otimes \textit{rhs.prelimString}$
        \State $\textit{node.cost} \gets \textit{alignCost} + \textit{lhs.cost} + \textit{rhs.cost}$
        \State $\textit{node.prelimString} \gets \textit{alignContext}$
      \EndIf
    \EndFunction
  \end{algorithmic}
\end{algorithm}


\section{Description of pre-order traversal for final alignments}
The preorder traversal of the binary tree $\mathcal{T}$ is a consumes the preliminary alignment context decorations added in the postorder traversal in order to assign final alignment context decorations to each node.
First the root node must be initialized for the preorder traversal by assigning the final alignment context as the preliminary alignment context with all deletion events replaced with substitution events.
This is required because at the root node, deletion events originated from  alignments of the left subtree and insertion events originated from alignments of the right sub tree, however the origin of these events are indistinguishable at the root node.
By initializing the root node in this manner, we treat the root node the same as we would any other parental node when deriving the internal node alignments.

We first check if the current node is the left or right child of it's parent.
If it is the left child, then each deletion event of the parent node's final alignment context is changed to an insertion event and each insertion event is changed to a deletion event.
This is required because deletion events originate from alignments of the left subtree and insertion events originate from alignments of the right subtree, however we must consider the converse for the resulting alignment to be consistent when assigning the final alignment context to a node which is the left child of it's parent.

Once the parental final alignment context has been correctly initialized based on where the current node is the right or left child of it's parent, we proceed to assign the final alignment context of the current node.
The parental final alignment context will nescessarily be of greater than or equal length to the parental preliminary alignment context and the current node's preliminary alignment context.
The resulting value assigned to the current node's final alignmnet context will have the same length as the parental final alignment context.
Since this invariant is maintained from the root node to the leaf node's final alignment context asssignments, all alignments will have the same length.
This constitutes a simple inductive proof that all node's final alignment assignments will be of equal length and costitute a genuine string alignment.

The final alignment context for the current node is derived by performing a ``sliding zip'' over the parental final alignment assignment, the parental preliminary alignment context, and the current node's perliminary alignment context.
The parental final alignment context is used as the basis of the zip.
At each step of the ``sliding zip'' one element of the parental final alignment context will be consumed and one element of the current node's final alignment context will be defined.
Additionally, one element of either the parental preliminary alignment context, the current node's preliminary alignment context, or both elements will also be consumed in each step of the ``sliding zip.''
The process is called a ``sliding zip'' because the elements of the parental and curent node's prelimary alignment contexts do not have a fixed index to which they correspond to the parental final alignment context being used as the basis of the zip.
Rather the elements of the parental and curent node's prelimary alignment contexts ``slide'' through the zipping process, and their corrsponding index with the basis is deduced dynamically.
Deletion events in the parental final alignment context are propogated to the current node's final alingment context without consuming elements of the parental or curent node's perliminary alignment contexts.
For each non-deletion element in the parental final alignment context, one element from either the parental preliminary context or the current node's preliminary context, or both elements are consumed to determine which element is added to the current node's final alignment context depending on the deletion, insertion, or alignment event of the next parental preliminary alignment context element.
However, the final alignment context assignments for internal nodes and leaf nodes are defined slightly differently within the ``sliding zip.''

\begin{itemize}

\item If the next element of the parental final alignment context is a deletion event, consume the parental final alignment element and add a deletion event to the current node's final alignment context.

\item If the next element of the parental final alignment context is an insertion or alignment event and the next element of the parental preliminary alignment context is a deletion event, then we consume both elements and add a deletion event to the current node's final alignment context.

\item If the next element of the parental final alignment context is an insertion event and the next element of the parental preliminary alignment context is an alignment event, then we consume both elements along with the next element of the current node's preliminary alignment context and add the consumed element of the current node's preliminary alignment context to the current node's final alignment context.

\item If the next element of the parental final alignment context is an insertion event and the next element of the parental preliminary alignment context is an insertion event and we are deriving the alignment of a leaf node, then we must inspect the median value of the next element of the current node's preliminary alignment context.
If the median value is \textit{not} the same as the inserted value from the parental preliminary alignment context, then we consume both the parental final alignment context and the parental preliminary alignment context elements and add a deletion event to the current node's final alignment context. 
If the median value is the same as the inserted value from the parental preliminary alignment context or we are not deriving the alignment of a aligning a leaf node, then we consume all three elements along and add the consumed element of the current node's preliminary alignment context to the current node's final alignment context, converting a deletion event to an insertion event if the consumed element of the current node's preliminary alignment was a deletion event.

\item If the next element of the parental final alignment context is an alignment event and the next element of the parental preliminary alignment context is an insertion event, then we consume both elements along with the next element of the current node's preliminary alignment context and add the consumed element of the current node's preliminary alignment context to the current node's final alignment context.

\item If the next element of the parental final alignment context is an alignment event and the next element of the parental preliminary alignment context is an alignment event, we must check if we are deriving the alignment for a leaf node.
If we are deriving the alignment for a leaf node, then we consume both elements along with the next element of the current node's preliminary alignment context and add the consumed element of the current node's preliminary alignment context to the current node's final alignment context.
If we are \textit{not} deriving the alignment for a leaf node, then we consume both elements along with the next element of the current node's preliminary alignment context and add the consumed element of the parental preliminary alignment context to the current node's final alignment context.

\end{itemize}

\textbf{TODO} add analysis and summary here.
The major difference is the additional stored information allows us to decorate the final assignments without performing another string alignment on each edge.
This allows the pre-order assignments to be assigned in $\mathcal{O}(n*k)$ instead of $\mathcal{O}(n*k^2)$ time.
Note that this can be performed simultaneously with an implied alignment pass described in the next section.

\section{Description of pre-order traversal for implied alignments}
\textbf{TODO}
Here I will describe in the pre-order traversal for implied alignments. I will again note the isomorphism between binary trees and the associative ordering of a binary operation. 
We will use the preliminary alignment contexts from the post order traversal to assign an implied alignment to each node. 
I will note the similarity and difference to implied alignment derivation mentioned by Ward's previous works. 
The major difference is the additional stored information allows us to decorate the final assignments in $\mathcal{O}(n*k^{2-c})$ instead of $\mathcal{O}(n*k^2)$ time.

Here we describe in the most general mathematical detail the nature of dynamic homologies and how the monoid structure can be used to reconstruct the intermediate alignments on internal edges.


\section{Pseudocode of pre-order traversal}

\begin{algorithm}
  \caption{Pre-order Traversal}\label{preOrder}
  \begin{algorithmic}[1]
    \Require{      A binary tree decorated with leaf     labels $inputString   \in \Sigma_{\Gamma}^{*}$}
    \Require{      A binary tree decorated with internal labels $prelimString  \in \Sigma_{\Gamma}^{*}$}
    \Ensure {$\;\;$A binary tree decorated with leaf     labels $alignedString \in \Sigma_{\Gamma}^{*}$}
    \Ensure {$\;\;$A binary tree decorated with internal labels $finalString   \in \Sigma_{\Gamma}^{*}$}
    \Function{preOrder}{$\textit{node}$}
      \If    {isRoot ( $\textit{node}$ )} \Comment{Initialize the root node}
        \State $\textit{node.finalString} \gets \Call{initializeRootString}{\textit{node.prelimString}}$
      \Else
        \State $\textit{parentFinal} \;\;\; \gets \textit{node.parent.finalString}$
        \State $\textit{parentPrelim}    \, \gets \textit{node.parent.prelimString}$
        \State $\textit{childPrelim} \;\;\;\, \gets \textit{node.prelimString}$
        \If {isLeftChildOfParent($\textit{node}$)}
          \ForEach {$\textit{context} \in \textit{parentPrelim}$}
            \State \Call{reverseContext}{$\textit{context}$}
          \EndFor
        \EndIf
        \State $\textit{v} \gets$ \Call{deriveAlignment}{$isLeaf ( \textit{node} ), \textit{parentFinal}, \textit{parentPrelim}, \textit{childPrelim}$}
        \State $\textit{node.finalString} \gets \textit{v}$
      \EndIf
    \EndFunction

    \Function{initializeRootString}{$\textit{rootString}$}
      \ForEach {$\textit{context} \in \textit{rootString}$}
        \Call{deletionToInsertion}{$\textit{context}$}
      \EndFor
    \EndFunction
      
    \Function{deletionToInsertion}{$\textit{context}$}
      \Switch{$\textit{context}$}
        \Case{$\textbf{DELETE} \;\; \textit{m} \;\; \textit{x} \;\;$}
          \Return $\textbf{INSERT} \;\; \textit{m} \;\; \textit{x} \;\;$
        \EndCase
        \Case{$\textit{v} \;\;$}
          \Return $\textit{v}$
        \EndCase
      \EndSwitch
    \EndFunction

    \Function{reverseContext}{$\textit{context}$}
      \Switch{$\textit{context}$}
        \Case{    $\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
          \Return $\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{y} \;\; \textit{x} \;\;$
        \EndCase
        \Case{    $\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
          \Return $\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{x} \;\;$
        \EndCase
        \Case{    $\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
          \Return $\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{y} \;\;$
        \EndCase
      \EndSwitch
    \EndFunction
  \end{algorithmic}
\end{algorithm}


%\begin{algorithm}
%  \caption{Internal Node Alignment}\label{alignInternal}
%  \begin{algorithmic}[1]      
%    \Function{alignInternal}{$\textit{pAlignment}, \textit{pContext}, \textit{cContext}$}
%      \State $\textit{del}   \;\;\quad \gets \textbf{DELETE}$ -- --
%      \State $\textit{len}   \;\;\quad \gets$ \Call{length}{$\textit{pAlignment}$}
%      \State $\textit{pcLen} \;        \gets$ \Call{length}{$\textit{pContext}$}
%      \State $\textit{ccLen} \;        \gets$ \Call{length}{$\textit{cContext}$}
%      \State $\left( \textit{i}, \textit{j}, \textit{k} \right) \gets \left( 0, 0, 0 \right)$
%      \For{$\textit{i} < \textit{len}$}
%        \If    {$\textit{i} \geq \textit{ccLen} \land \textit{i} \geq \textit{pcLen}$}
%          \State $\textit{result}_i \gets \textit{del}$
%        \ElsIf {$\textit{i} \geq \textit{ccLen}$}
%          \Switch{$\textit{pAlignment}_i$}
%            \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%              \State $\textit{result}_i \gets \textit{del}$
%            \EndCase
%            \Default{}
%              \State $\textit{result}_i \gets \textit{del}$
%              \State $\textit{j} \gets \textit{j} + 1$
%            \EndDefault
%          \EndSwitch
%        \Else
%          \Switch{$\textit{pAlignment}_i$}
%            \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%              \State $\textit{result}_i \gets \textit{del}$
%            \EndCase
%            \Case{$\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
%              \Switch{$\textit{pContext}_j$}
%                \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%                  \State $\textit{result}_i \gets \textit{del}$
%                \EndCase
%                \Case{$\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
%                  \State $\textit{result}_i \gets$ \Call{deletionToInsertion}{$\textit{cContext}_k$}
%                  \State $\textit{k} \gets \textit{k} + 1$
%                \EndCase
%                \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
%                  \State $\textit{result}_i \gets \textit{cContext}_k$
%                  \State $\textit{k} \gets \textit{k} + 1$
%                \EndCase
%              \EndSwitch
%              \State $\textit{j} \gets \textit{j} + 1$
%            \EndCase
%            \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
%              \Switch{$\textit{pContext}_j$}
%                \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%                  \State $\textit{result}_i \gets \textit{del}$
%                \EndCase
%                \Case{$\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
%                  \State $\textit{result}_i \gets \textit{cContext}_k$
%                  \State $\textit{k} \gets \textit{k} + 1$
%                \EndCase
%                \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
%                  \State $\textit{result}_i \gets \textit{pContext}_j$
%                  \State $\textit{k} \gets \textit{k} + 1$
%                \EndCase
%              \EndSwitch
%              \State $\textit{j} \gets \textit{j} + 1$
%            \EndCase
%          \EndSwitch
%        \EndIf  
%        \State $\textit{i} \gets \textit{i} + 1$
%      \EndFor
%      \Return $\textit{result}$
%    \EndFunction
%  \end{algorithmic}
%\end{algorithm}

%\begin{algorithm}
%  \caption{Leaf Node Alignment}\label{alignLeaf}
%  \begin{algorithmic}[1]
%    \Function{alignLeaf}{$\textit{pAlignment}, \textit{pContext}, \textit{cContext}$}
%      \State $\textit{del}   \;\;\quad \gets \textbf{DELETE}$ -- --
%      \State $\textit{len}   \;\;\quad \gets$ \Call{length}{$\textit{pAlignment}$}
%      \State $\textit{pcLen} \;        \gets$ \Call{length}{$\textit{pContext}$}
%      \State $\textit{ccLen} \;        \gets$ \Call{length}{$\textit{cContext}$}
%      \State $\left( \textit{i}, \textit{j}, \textit{k} \right) \gets \left( 0, 0, 0 \right)$
%      \For{$\textit{i} < \textit{len}$}
%        \If    {$\textit{i} \geq \textit{ccLen} \land \textit{i} \geq \textit{pcLen}$}
%          \Switch{$\textit{pAlignment}_i$}
%            \Case{$\textbf{DELETE} \;\;     \textit{m} \;\;      \textit{x} \;\;\quad$}
%              \State $\textit{result}_i \gets \textit{del}$
%            \EndCase
%            \Case{$\textbf{INSERT} \;\;\;\, \textit{m} \;\;      \textit{x} \;\;\quad$}
%              \State $\textit{result}_i \gets \textit{del}$
%            \EndCase
%          \EndSwitch
%        \ElsIf {$\textit{i} \geq \textit{ccLen}$}
%          \Switch{$\textit{pAlignment}_i$}
%            \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%              \State $\textit{result}_i \gets \textit{del}$
%            \EndCase
%            \Default{}
%              \State $\textit{result}_i \gets \textit{del}$
%              \State $\textit{j} \gets \textit{j} + 1$
%            \EndDefault
%          \EndSwitch
          
%        \Else
%          \Switch{$\textit{pAlignment}_i$}
%            \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%              \State $\textit{result}_i \gets \textit{del}$
%            \EndCase
%            \Case{$\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
%              \Switch{$\textit{pContext}_j$}
%                \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%                  \State $\textit{result}_i \gets \textit{del}$
%                \EndCase
%                \Case{$\textbf{INSER1T} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
%                  \If {y = \Call{getMedian}{$\textit{cContext}_k$}}
%                    \State $\textit{result}_i \gets \textit{cContext}_k$
%                    \State $\textit{k} \gets \textit{k} + 1$
%                  \Else
%                    \State $\textit{result}_i \gets \textit{del}$
                  
%                  \EndIf
%                \EndCase
%                \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
%                  \State $\textit{result}_i \gets \textit{cContext}_k$
%                  \State $\textit{k} \gets \textit{k} + 1$
%                \EndCase
%              \EndSwitch
%              \State $\textit{j} \gets \textit{j} + 1$
%            \EndCase
%            \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
%              \Switch{$\textit{pContext}_j$}
%                \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
%                  \State $\textit{result}_i \gets \textit{del}$
%                \EndCase
%                \Default{}
%                  \State $\textit{result}_i \gets \textit{cContext}_k$
%                  \State $\textit{k} \gets \textit{k} + 1$
%                \EndDefault                
%              \EndSwitch
%              \State $\textit{j} \gets \textit{j} + 1$
%            \EndCase
%          \EndSwitch
%        \EndIf  
%        \State $\textit{i} \gets \textit{i} + 1$
%      \EndFor
%      \Return $\textit{result}$
%    \EndFunction
%  \end{algorithmic}
%\end{algorithm}

\newgeometry{top=1mm, bottom=1mm}

\begin{algorithm}
  \caption{Internal Node Alignment}\label{deriveAlignment}
  \begin{algorithmic}[1]      
    \Function{deriveAlignment}{$\textit{isLeaf}, \textit{pAlignment}, \textit{pContext}, \textit{cContext}$}
      \State $\textit{del}   \;\;\quad \gets \textbf{DELETE}$ -- --
      \State $\textit{len}   \;\;\quad \gets$ \Call{length}{$\textit{pAlignment}$}
      \State $\textit{pcLen} \;        \gets$ \Call{length}{$\textit{pContext}$}
      \State $\textit{ccLen} \;        \gets$ \Call{length}{$\textit{cContext}$}
      \State $\left( \textit{i}, \textit{j}, \textit{k} \right) \gets \left( 0, 0, 0 \right)$
      \For{$\textit{i} < \textit{len}$}
        \If    {$\textit{j} \geq \textit{pcLen} \land \textit{k} \geq \textit{ccLen}$}
          \State $\textit{result}_i \gets \textit{del}$
        \ElsIf {$\textit{k} \geq \textit{ccLen}$}
          \Switch{$\textit{pAlignment}_i$}
            \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
              \State $\textit{result}_i \gets \textit{del}$
            \EndCase
            \Default{}
              \State $\textit{result}_i \gets \textit{del}$
              \State $\textit{j} \gets \textit{j} + 1$
            \EndDefault
          \EndSwitch
        \Else
          \Switch{$\textit{pAlignment}_i$}
            \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
              \State $\textit{result}_i \gets \textit{del}$
            \EndCase
            \Case{$\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
              \Switch{$\textit{pContext}_j$}
                \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
                  \State $\textit{result}_i \gets \textit{del}$
                \EndCase
                \Case{$\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
                  \If {$\textit{isLeaf} \land y \neq \;$\Call{getMedian}{$\textit{cContext}_k$}}
                    \State $\textit{result}_i \gets \textit{del}$
                  \Else
                    \State $\textit{result}_i \gets$ \Call{deletionToInsertion}{$\textit{cContext}_k$}
                    \State $\textit{k} \gets \textit{k} + 1$
                  \EndIf
                \EndCase
                \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
                  \State $\textit{result}_i \gets \textit{cContext}_k$
                  \State $\textit{k} \gets \textit{k} + 1$
                \EndCase
              \EndSwitch
              \State $\textit{j} \gets \textit{j} + 1$
            \EndCase
            \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
              \Switch{$\textit{pContext}_j$}
                \Case{$\textbf{DELETE} \;\;   \textit{m} \;\;      \textit{x} \;\;\quad$}
                  \State $\textit{result}_i \gets \textit{del}$
                \EndCase
                \Case{$\textbf{INSERT} \;\;\; \textit{m} \;\;\quad \textit{y} \;\;$}
                  \State $\textit{result}_i \gets \textit{cContext}_k$
                  \State $\textit{k} \gets \textit{k} + 1$
                \EndCase
                \Case{$\textbf{ALIGN} \quad\; \textit{m} \;\;      \textit{x} \;\; \textit{y} \;\;$}
                  \If {$\textit{isLeaf}$}
                    \State $\textit{result}_i \gets \textit{pContext}_k$
                  \Else
                    \State $\textit{result}_i \gets \textit{pContext}_j$
                  \EndIf
                    \State $\textit{k} \gets \textit{k} + 1$
                \EndCase
              \EndSwitch
              \State $\textit{j} \gets \textit{j} + 1$
            \EndCase
          \EndSwitch
        \EndIf  
        \State $\textit{i} \gets \textit{i} + 1$
      \EndFor
      \Return $\textit{result}$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\restoregeometry

\section{Conclusion and Empirical Examples}
\textbf{TODO}
I hope that we can provide data set examples describing how the algorithm runs faster.

We ran the implied alignment algorithm described in this paper on fungi and metazoa biological data sets to show the runtime performance of the preorder traversal. 
Both full data sets consisted of a pre-selected tree and pre-deterimined string alignment.
The full leaf set of the tree was repeatedly pruned in half to produce a data set of doubling leaf set sizes.
The string alignment was repeatedly truncated, dropping the beginning and end of the alignment, taking the central slice of the correct length from each string, and then removing all the gaps from the alignment slice.
The pruned trees and truncated strings were used as progressively doubling inputs, to measure runtime scaling in terms of both leaf set size and string length.

Additionally, a pathological data-set was constructed to exemplify the worst case performance of the implied alignment algorithm.
The pathological data-set consisted of balanced binary trees which repeatedly doubled in size.
This strings of the pathological data-set consisted of a single symbol repeated a specific number of times, each string with a different character.
The lengths of the strings containing many copies of a single character were repeatedly doubled in size.
The runtime scaling of this data set was run under two different metrics $\sigma_1$ \& $\sigma_2$.
The former would prefer substitution events over insertion or deletion events and would scale well.
The latter would prefer insertion or deletion events over substitution events and would produce the degenerate string alignment.

\begin{table}[!hbt]
\begin{center}
\begin{tabular}{c|ccccc}
$\sigma_1$ & A & C & G & T & -- \\ \hline 
        A  & 0 & 1 & 1 & 1 & 2  \\
        C  & 1 & 0 & 1 & 1 & 2  \\
        G  & 1 & 1 & 0 & 1 & 2  \\
        T  & 1 & 1 & 1 & 0 & 2  \\
        -- & 2 & 2 & 2 & 2 & 0
\end{tabular}
\caption{Metric costs $\sigma_1$, prefer Align}
\label{tab1}
\end{center}
\end{table}

\begin{table}[!hbt]
\begin{center}
\begin{tabular}{c|ccccc}
$\sigma_2$ & A & C & G & T & -- \\ \hline 
        A  & 0 & 3 & 3 & 3 & 1  \\
        C  & 3 & 0 & 3 & 3 & 1  \\
        G  & 3 & 3 & 0 & 3 & 1  \\
        T  & 3 & 3 & 3 & 0 & 1  \\
        -- & 1 & 1 & 1 & 1 & 0
\end{tabular}
\caption{Metric costs $\sigma_2$, prefer Insert/Delete}
\label{tab1}
\end{center}
\end{table}


\section{Why the algorithm is named Implied Alignment}
The algorithm described by Wheeler is was named implied alignment because it allows us to derive an alignment that is implied by the binary tree on a given leaf-set. 
However, it is worth articulating exactly how the alignment we derive is \emph{implied} by the tree. 
In short, it is the lack of associativity of the heuristic function $\oplus$.

If we were given a rooted binary tree $\mathcal{T} = ((A,B),(C,D))$ with leaves $A, B, C, D \in \Sigma^{*}$ then the ancestoral state of the root node defined by the heuristic function $\oplus$ would be $((A \oplus B) \oplus (C \oplus D))$. 
In fact, the ancestral state of any internal node defined by the heuristic function $\oplus$ can be calculated by applying $\oplus$ recursively to the subtree of the internal node. 
The binary structure of the tree directly implies the precedence of each application of the heuristic function $\oplus$ in the final result. Since the heuristic function $\oplus$ need not be associative, the tree $((A,(B,C)),D)$ evaluated as $((A \oplus (B \oplus C)) \oplus D)$, is likely to yield different results. 
However, since the heuristic function $\oplus$ is commutative, transposing any child nodes between the left and right positions of their parent will result in a tree that yields the same internal values. 
For example consider such a transposed tree $\mathcal{T'}$:

\begin{align*}
  eval(\mathcal{T'}) &= eval((D,C),(B,A))
\\  &= ((D \oplus C) \oplus (B \oplus A))
\\  &= ((C \oplus D) \oplus (B \oplus A))
\\  &= ((C \oplus D) \oplus (A \oplus B))
\\  &= ((A \oplus B) \oplus (C \oplus D))
\\  &= eval((A,B),(C,D))
\\  &= eval(\mathcal{T})
\end{align*}

This commutative property and lack of an associative property is why the alignment is implied by the tree on the leaf-set under the heuristic function $\oplus$ and not the unique alignment on all trees for the leaf-set under the heuristic function $\oplus$. 
Proof that a heuristic function $\oplus$ that is both commutative \emph{and} associative using the algorithm described in this paper would yield the same alignment on all trees for a given leaf-set is left as an exercise to the reader.

String alignment is of paramount importance in phylogenetic search, though when the string alignment occurs can be a matter of contention.
Traditionally strings are aligned first, and that alignment is held constant as a phylogenetic tree is searched for on this alignment.
A more modern method of dynamic homology has been decribed by \citep{Wheeler1996}, in which string are not pre-aligned, but rather the strings are aligned on the current tree under consideration in the phylogentic search via implied alignment.
How the a string alignment is used in a phylogenetic search leads to an important distiction in interpreting the meaning of the resulting string alignment.
When performing the traditional methodology of aligning strings then searching on the static alignment, the resulting topology of the phylogenetic search is implied by the inital alignment.
When using implied alignment to search on a dynamic homology, the alignments depend on the toplogy.

See figure from this other paper Ward will note, as a good example of how Implied Alignment differs from a traditional multiple sequece aligment algorithm.


\section{Future work}
If a heuristic function $\otimes$ that was both commutative and associative and with sufficiently low error could be defined, then the iterative approximation (citation here) method described by Ward Wheeler could be dramatically improved upon. 
Even an incredibly expensive, poly-time heuristic function $\otimes$ would have it's cost amortized over the tree-space search because the heuristic would only need to be applied once to a dynamic homology and then an implied alignment generated which would be the same for all trees in the tree space. 
The iterative approximation would cease needing to be iterative and rather be an \emph{invariant} approximation.

\section{Acknowledgements}
This work was supported by DARPA SIMPLEX (``Integrating Linguistic, Ethnographic, and Genetic Information of Human Populations: Databases and Tools,'' DARPA-BAA-14-59 SIMPLEX TA-2, 2015-2018) and Robert J. Kleberg Jr. and Helen C. Kleberg foundation grant ``Mechanistic Analyses of Pancreatic Cancer Evolution''. 
\newpage
\bibliography{big-refs-3}

\end{document}
\grid
\grid
